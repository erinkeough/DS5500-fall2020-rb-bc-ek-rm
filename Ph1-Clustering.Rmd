---
title: "DS 5500 Capstone EDA"
author: "Erin Keough"
date: "10/2/2020"
output: pdf_document
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(cluster)
library(factoextra)
library(dplyr)
```



# K-means Clustering

```{r Preparing, message=FALSE, warning=FALSE}

#bos <- read_csv("bos_all.csv")
bos <- read_csv("census-csv/prop_change_suffolk_labeled.csv")
head(bos)

# Removing rows with missing data --> 119 obs of 19 variables using bos_all
#tempbos <- na.omit(bos)
# NOTE: no NA entried in the census_suffolk_standardized set 

# ###########################################
# THE FOLLOWING IS FOR BOS_ALL -- IGNORED
# ###########################################
# Prepping the data:
#locations <- tempbos[, c(4, 13)] # Retain location details & GEOID
#vars <- tempbos[, c(1:3, 5:12, 14:19)] # Extract numeric data
#rownames(vars) <- locations$GEOID # Rename rows --> GEOID

# For cesus_suffolk_standardized:
vars <- bos[, 9:260]
# Standardization:
vars_scaled <- as.tibble(scale(vars))
rownames(vars_scaled) <- bos$Census.Tract.Code # Rename rows --> Census tract code
#head(vars_scaled)

```


```{r kMeans}

# Correlation matrix:
fviz_dist(get_dist(vars_scaled), gradient = list(low = "cyan3", 
                                                 mid = "white", 
                                                 high = "coral1"))

# ###################
# K-means clustering
# ###################
k2 <- kmeans(vars_scaled, centers = 2, nstart = 25)
k3 <- kmeans(vars_scaled, centers = 3, nstart = 25)
k4 <- kmeans(vars_scaled, centers = 4, nstart = 25)
k5 <- kmeans(vars_scaled, centers = 5, nstart = 25)

plotk2 <- fviz_cluster(k2, data = vars_scaled, geom = "point") +
  ggtitle("k = 2") + theme(plot.title = element_text(hjust = 0.5))
plotk3 <- fviz_cluster(k3, data = vars_scaled, geom = "point") +
  ggtitle("k = 3") + theme(plot.title = element_text(hjust = 0.5))
plotk4 <- fviz_cluster(k4, data = vars_scaled, geom = "point") +
  ggtitle("k = 4") + theme(plot.title = element_text(hjust = 0.5))
plotk5 <- fviz_cluster(k5, data = vars_scaled, geom = "point") +
  ggtitle("k = 5") + theme(plot.title = element_text(hjust = 0.5))

library(gridExtra)
grid.arrange(plotk2, plotk3, plotk4, plotk5, nrow = 2)

```


# Determining the optimal number of clusters

## Elbow Method

Here, we can compute the optimal number of clusters following these steps:
  1. Performing k-means on the data with varying numbers of clusters, k
  2. Calculate the total within-cluster sum of squares for each k
  3. Plot the curve of within-cluster sum of squares based on k

The optimal number of clusters is indicated on the graph by the "knee" of the plot, or the point where the reduction in WSS becomes less dramatic.


```{r Elbow}

set.seed(1)

# Function to compute the total within-cluster sum of squares:
wss <- function(k) {
  kmeans(vars_scaled, centers = k, nstart = 25)$tot.withinss
}

# Compute and plot the within-cluster sum of squares for k = 1 to 15:
kvals <- 1:15
# Compute WSS for 2 to 15 clusters by mapping the defined WSS function:
wssvals <- map_dbl(kvals, wss)

df <- data.frame(kvals, wssvals)

# Plot the results:
ggplot(df) +
  geom_point(aes(kvals, wssvals), color = "darkcyan", size = 2) +
  geom_line(aes(kvals, wssvals), color = "gray30") +
  labs(x = "Number of Clusters", y = "Total WSS",
       title = "Total Within-cluster Sum of Squares 
based on Number of Clusters") +
  theme(plot.title = element_text(hjust = 0.5))


# ### This function apparently does the same thing as the above code:

fviz_nbclust(vars_scaled, kmeans, method = "wss") + 
  theme(plot.title = element_text(hjust = 0.5))

```

This method gave us some insights, but it could be argued that either 3 or 5 clusters could be used with our data for the best results, so we'll try some other methods to be sure.

**For the new dataset** - The optimal number of clusters seems to be 2, but to be sure, we'll check other methods.


## Average Silhouette Method

This method measures the the quality of the clustering by seeing how well each object lies within its cluster. To do so, we look for the number of clusters that maximizes the average silhouette over a range of possible values for k.


```{r avgSilhouette}

fviz_nbclust(vars_scaled, kmeans, method = "silhouette") +
  theme(plot.title = element_text(hjust = 0.5))

```

This seems to confirm that 3 clusters is optimal for performing clustering on our data, but to be certain, I will look into another determination method.

**For the new dataset** - This method also seems to name 2 clusters as the optimal number.


## Gap Statistic Method

This method compares the total intracluster variation for different values of k with their expected values under null reference distribution of the data, or the distribution with no obvious clustering.

```{r gapStat}

set.seed(1)

# Compute gap statistics
gap <- clusGap(vars_scaled, FUN = kmeans, nstart = 25, K.max = 10, B = 50)

# Plot the results:
fviz_gap_stat(gap) + theme(plot.title = element_text(hjust = 0.5))

```

Under the circumstances of our data, this is clearly an unreliable approach to determining the optimal number of clusters. With the previous two methods suggesting 3 clusters, we will proceed with k = 3.

**For the new dataset** - Again, this is a bit of a wildcard, naming 9 as the optimal number of clusters, so we will proceed with 2 for this new dataset.


```{r clusterStats}

fviz_cluster(k2, data = vars_scaled, geom = "point") +
  ggtitle("k = 2") + theme(plot.title = element_text(hjust = 0.5))

# Inter-cluster means for all variables in the non-scaled data:
vars %>%
  mutate(Cluster = k2$cluster) %>%
  group_by(Cluster) %>%
  summarise_all("mean")

```


# Next steps: k-means based on Census year

I will now separate the data based on which year of the Census survey the data is based on in order to examine the differences in clusters over time.


## Gathering the data -- bos_all dataset

```{r Prep2}

# Data by decade:
d90 <- tempbos[, c(14:19)]
d00 <- tempbos[, c(1:3, 5)]
d10 <- tempbos[, c(6:12)]

# Name rows by GEOID:
rownames(d90) <- locations$GEOID
rownames(d00) <- locations$GEOID
rownames(d10) <- locations$GEOID

# Scale data:
d90scaled <- scale(d90)
d00scaled <- scale(d00)
d10scaled <- scale(d10)

```


## Gathering the data -- census_suffolk_standardized dataset

```{r Prep3}

# Data by decade:
d90 <- bos %>% select(contains("1990"))
d00 <- bos %>% select(contains("2000"))
d10 <- bos %>% select(contains("2010"))

# Name rows by GEOID:
rownames(d90) <- bos$Census.Tract.Code
rownames(d00) <- bos$Census.Tract.Code
rownames(d10) <- bos$Census.Tract.Code

# Scale data:
d90scaled <- scale(d90)
d00scaled <- scale(d00)
d10scaled <- scale(d10)

```


## Visualize clusters over time -- bos_all data

I'll start by assuming the number of optimal clusters remains to be 3.

```{r}

k3d90 <- kmeans(d90scaled, centers = 3, nstart = 25)
k3d00 <- kmeans(d00scaled, centers = 3, nstart = 25)
k3d10 <- kmeans(d10scaled, centers = 3, nstart = 25)

plot90 <- fviz_cluster(k3d90, data = d90scaled, geom = "point") +
  ggtitle("1990 Data with k = 3 Clusters") + 
  theme(plot.title = element_text(hjust = 0.5))
plot00 <- fviz_cluster(k3d00, data = d00scaled, geom = "point") +
  ggtitle("2000 Data with k = 3 Clusters") + 
  theme(plot.title = element_text(hjust = 0.5))
plot10 <- fviz_cluster(k3d10, data = d10scaled, geom = "point") +
  ggtitle("2010 Data with k = 3 Clusters") + 
  theme(plot.title = element_text(hjust = 0.5))

grid.arrange(plot90, plot00, plot10, nrow = 1)

```

There seems to be a fairly significant difference among the clusters from 1990 to 2010, so we will have to look into what factors are attributed to this shift.


## Visualize clusters over time -- census_suffolk_standardized data

```{r}

k2d90 <- kmeans(d90scaled, centers = 2, nstart = 25)
k2d00 <- kmeans(d00scaled, centers = 2, nstart = 25)
k2d10 <- kmeans(d10scaled, centers = 2, nstart = 25)

plot90 <- fviz_cluster(k2d90, data = d90scaled, geom = "point") +
  ggtitle("1990 Data with k = 2 Clusters") + 
  theme(plot.title = element_text(hjust = 0.5))
plot00 <- fviz_cluster(k2d00, data = d00scaled, geom = "point") +
  ggtitle("2000 Data with k = 2 Clusters") + 
  theme(plot.title = element_text(hjust = 0.5))
plot10 <- fviz_cluster(k2d10, data = d10scaled, geom = "point") +
  ggtitle("2010 Data with k = 2 Clusters") + 
  theme(plot.title = element_text(hjust = 0.5))

grid.arrange(plot90, plot00, plot10, nrow = 1)


comp90 <- d90 %>%
  mutate(Cluster = k2d90$cluster) %>%
  group_by(Cluster) %>%
  summarise_all("mean")

```


# Hierarchical Clustering -- bos_all data

```{r}

# 1990 
dist90 <- dist(d90scaled)
hc90 <- hclust(dist90)
plot(hc90, cex = 0.65)

# 2000 
dist00 <- dist(d00scaled)
hc00 <- hclust(dist00)
plot(hc00, cex = 0.65)

# 2010 
dist10 <- dist(d10scaled)
hc10 <- hclust(dist10)
plot(hc10, cex = 0.65)

```


# Hierarchical Clustering -- census_suffolk_standardized data

```{r}

# ALL:
distbos <- dist(vars_scaled)
hcbos <- hclust(distbos)
plot(hcbos, cex = 0.65, main = NULL) + 
  title(main = "Cluster Dendrogram for Boston Census Tracts")

# Scale data:
d90scaled <- scale(d90)

# 1990 
dist90 <- dist(d90scaled)
hc90 <- hclust(dist90)
plot(hc90, cex = 0.65, main = NULL) +
  title(main = "1990 Cluster Dendrogram")

# 2000 
dist00 <- dist(d00scaled)
hc00 <- hclust(dist00)
plot(hc00, cex = 0.65, main = NULL) +
  title(main = "2000 Cluster Dendrogram")

# 2010 
dist10 <- dist(d10scaled)
hc10 <- hclust(dist10)
plot(hc10, cex = 0.65, main = NULL) +
  title(main = "2010 Cluster Dendrogram")

```


# Plotting clusters in Boston geography

```{r message=FALSE, warning=FALSE}

# Read in Massachusetts data
tractsMA <- read_csv("census-csv/tracts_geography.csv") %>% filter(USPS == "MA")

# Keep only Suffolk County (FIPS: 25025)
tracts <- tractsMA[grepl("^25025", tractsMA$GEOID), ]
# Derive the GEOID from the tract codes
bos$GEOID <- as.numeric(paste(25025, 
                                  sprintf("%06d", bos$Census.Tract.Code),
                                  sep = ""
                                  )
                            )
# Join datasets on GEOID
geo <- bos %>% left_join(tracts) %>% as.data.frame() 
# Add cluster assignments from k-means
geo$Cluster1990 <- k2d90$cluster
geo$Cluster2000 <- k2d00$cluster
geo$Cluster2010 <- k2d10$cluster

library(ggmap)

# ################################################################################
# NOTE : THIS METHOD PRODUCES PRETTY LOW-RES MAPS, THIS WAS A PLACEHOLDER UNTIL I 
# COULD GET THE NEXT SECTION OF CODE TO WORK
# ################################################################################

# Coordinate box around Boston
bbox <- c(left = -71.165, bottom = 42.23, right = -71.0, top = 42.425)
ggmap(get_stamenmap(bbox, zoom = 10, maptype = "terrain-lines")) + 
  geom_point(data = geo, aes(x = INTPTLONG, y = INTPTLAT, 
                             color = as.factor(Cluster1990))) +
  labs(x = "Longitude", y = "Latitude", title = "1990 Boston Neighborhood Clusters",
       color = "Cluster") +
  theme(plot.title = element_text(hjust = 0.5))
  
```


```{r}

# Connect to Google APIs with your key:
ggmap::register_google(key = "YOUR KEY")

# Determine the coordinates of Boston:
center <- geocode("Boston, Massachusetts", source = "google")

# Generate the Google map of Boston:
bosmap <- qmap(c(lon = center$lon, lat = center$lat), zoom = 12)
bosmap + 
  geom_point(data = geo, aes(x = INTPTLONG, y = INTPTLAT, 
                             color = as.factor(geo$Cluster2010), size = 2)) +
  scale_color_manual(breaks = c("1", "2"), values = c("darkgoldenrod1", "darkorchid4")) +
  scale_size(guide = 'none') +
  labs(title = "2010 Boston Neighborhood Clusters", color = "Cluster") +
  theme(plot.title = element_text(hjust = 0.5))

```





























